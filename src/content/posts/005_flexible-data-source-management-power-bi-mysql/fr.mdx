---
title: "Gestion flexible des sources de donn√©es dans Power BI avec MySQL"
description: "A practical approach to dynamically manage data sources in Power BI, switching between MySQL and CSV based on the environment to optimize connectivity and performance. üöÄ"
pubDate: "Jan 24 2025"
tags: ["Power BI", "Power Query", "MySQL", "CSV", "Optimisation"]
lang: "fr"
heroImage: "https://github.com/user-attachments/assets/fc5d50c3-248d-4807-b1c1-8d45baddf6da"
giscusTitleDiscussionsMapping: "Flexible Data Source Management in Power BI with MySQL"
draft: true
---

import FileTree from "@src/components/FileTree.astro";
import FileItem from "@src/components/FileItem.astro";
import FolderItem from "@src/components/FolderItem.astro";
import Link from "@src/components/Link.astro";
import Note from "@src/components/Note.astro";

### Table des mati√®res

- [Introduction](#introduction)
- [Probl√©matiques rencontr√©es](#probl√©matiques-rencontr√©es)
  - [1. Probl√®mes de connectivit√©](#1-probl√®mes-de-connectivit√©)
  - [2. Performance et volume de donn√©es](#2-performance-et-volume-de-donn√©es)
- [Solution mise en place](#solution-mise-en-place)
  - [1. Architecture de la solution](#1-architecture-de-la-solution)
  - [2. Pr√©paration des donn√©es](#2-pr√©paration-des-donn√©es)
  - [3. Configuration des param√®tres](#3-configuration-des-param√®tres)
- [Impl√©mentation technique](#impl√©mentation-technique)
  - [1. Variable dynamique de d√©tection d'environnement](#1-variable-dynamique-de-d√©tection-denvironnement)
  - [2. Fonction GetData](#2-fonction-getdata)
  - [3. Utilisation de la Fonction GetData](#3-utilisation-de-la-fonction-getdata)
  - [4. Optimisation des Transformations des Donn√©es](#4-optimisation-des-transformations-des-donn√©es)
- [Conclusion](#conclusion)

<br />
### Introduction

Dans le cadre d‚Äôun projet pour l‚Äôun de nos clients, sur lequel je travaille actuellement (au moment de la r√©daction de cet article), nous avons √©t√© confront√©s √† un d√©fi int√©ressant sur la cr√©ation d‚Äôun tableau de bord Power BI connect√© √† une base de donn√©es MySQL contenant des millions de lignes. Cette exp√©rience nous a permis de d√©velopper une solution √©l√©gante pour g√©rer diff√©rentes sources de donn√©es en fonction de l‚Äôenvironnement de travail. Dans cet article, je vais vous pr√©senter les diff√©rentes √©tapes de construction de cette solution, en abordant les probl√©matiques rencontr√©es et les solutions mises en place.

### Probl√©matiques rencontr√©es

##### 1. Probl√®mes de connectivit√©

Apr√®s l'installation du driver MySQL pour Power Query, nous avons rencontr√© des difficult√©s de connexion li√©es √† la configuration du pare-feu sur le poste professionnel du client. Fait int√©ressant, la connexion fonctionnait parfaitement depuis mon ordinateur personnel et lors de l'actualisation des rapports dans le service Power BI.

##### 2. Performance et volume de donn√©es

La base de donn√©es contenait plusieurs millions de lignes, rendant le chargement local des donn√©es particuli√®rement chronophage. Cette situation n√©cessitait une approche alternative pour optimiser les performances en environnement de d√©veloppement.

### Solution mise en place

##### 1. Architecture de la solution

Pour r√©soudre ces probl√®mes, nous avons d√©velopp√© une approche hybride :

- En environnement local (Power BI Desktop) : utilisation de fichiers CSV stock√©s sur SharePoint
- En production (Power BI Service) : connexion directe √† la base de donn√©es MySQL

<br />
##### 2. Pr√©paration des donn√©es

Pour simplifier le d√©veloppement en local, nous avons d'abord r√©dig√© la requ√™te SQL permettant d'extraire les donn√©es n√©cessaires. Ensuite, nous avons con√ßu un script Python qui se connecte √† la base de donn√©es, ex√©cute la requ√™te, exporte les r√©sultats au format CSV, puis nous avons d√©pos√© les fichiers sur un site SharePoint.

##### 3. Configuration des param√®tres

Nous avons mis en place cinq param√®tres permettant de g√©rer dynamiquement les sources de donn√©es :

![parameters](https://github.com/user-attachments/assets/b83a1abc-b0a4-4a45-a980-6571bf7d88bc)

- **`ENVIRONMENT`** : choix entre LOCAL et PRODUCTION
- **`URL_CSV_FILE`** : lien vers le fichier CSV
- **`MySQL_HOSTNAME`** : nom d'h√¥te MySQL
- **`MySQL_DATABASE_NAME`** : nom de la base de donn√©es
- **`MySQL_QUERY`** : requ√™te SQL pr√©construite

<br />

### Impl√©mentation technique

##### 1. Variable dynamique de d√©tection d'environnement

Nous avons cr√©√© une variable dynamique bool√©enne `IS_PRODUCTION` qui simplifie la d√©tection de l'environnement :

![is_prod](https://github.com/user-attachments/assets/b008a278-203c-4c2a-bbe0-1e48310392ad)

```powerquery
let
    Source = Text.Contains(Text.Upper(ENVIRONMENT), "PROD")
in
    Source
```

Cette variable retourne automatiquement :

- `True` si le param√®tre ENVIRONMENT contient "PROD"
- `False` dans tous les autres cas

Cette approche nous permet d'utiliser simplement `IS_PRODUCTION` dans nos conditions plut√¥t que de r√©√©crire la formule compl√®te `Text.Contains(Text.Upper(ENVIRONMENT), "PROD")` √† chaque fois.

##### 2. Fonction GetData

Nous avons cr√©√© une fonction Power Query nomm√©e `GetData`, permettant de r√©cup√©rer les donn√©es depuis MySQL en production et depuis un fichier CSV en local.

![getdata](https://github.com/user-attachments/assets/487fa3bf-198b-418d-b560-a751998720ad)

```powerquery
let
    GetData = (NumberColumnsCSV as number, MySQLQuery as text) =>
        let
            CsvSource = Csv.Document(
                Web.Contents(URL_CSV_FILE),
                [
                    Delimiter = ",",
                    Columns = NumberColumnsCSV,
                    Encoding = 1252,
                    QuoteStyle = QuoteStyle.None
                ]
            ),
            CsvPromotedHeaders = Table.PromoteHeaders(CsvSource, [PromoteAllScalars = true]),

            SourceMySQL = MySQL.Database(
                MySQL_HOSTNAME,
                MySQL_DATABASE_NAME,
                [
                    ReturnSingleDatabase = true,
                    Query = MySQLQuery,
                    CreateNavigationProperties = false
                ]
            ),
            Result = if IS_PRODUCTION then SourceMySQL else CsvPromotedHeaders
        in
            Result
in
    GetData
```

Cette fonction r√©alise trois op√©rations essentielles :

1. **Chargement des donn√©es locales** :

   - R√©cup√®re un fichier CSV depuis une URL
   - Utilise un d√©limiteur de virgule
   - Sp√©cifie le nombre de colonnes
   - G√®re l'encodage et le style de citation
   - Promeut automatiquement la premi√®re ligne comme en-t√™tes

2. **Connexion √† la base de donn√©es** :

   - √âtablit une connexion √† MySQL en production
   - Ex√©cute une requ√™te SQL personnalis√©e
   - R√©cup√®re les donn√©es directement depuis la base

3. **S√©lection dynamique de la source** :

   - Bascule automatiquement entre CSV local et base MySQL
   - Utilise la variable `IS_PRODUCTION` comme crit√®re de s√©lection


<br />
##### 3. Utilisation de la Fonction GetData

Pour utiliser la fonction GetData, il suffit de cr√©er une nouvelle requ√™te et de la renommer comme vous le souhaitez. Dans cet exemple, nous l'appelons "MyData".

![mydata](https://github.com/user-attachments/assets/1425d395-2c12-498a-bb27-3731516e1b13)

```powerquery
let
    Source = GetData(5, MySQL_QUERY)
in
    Source
```


Cette approche permet de r√©cup√©rer les donn√©es en sp√©cifiant uniquement deux arguments :

- Le nombre de colonnes du fichier CSV (5 dans cet exemple)
- La requ√™te MySQL √† ex√©cuter (via le param√®tre MySQL_QUERY)

<br />
*c'est simple, n'est-ce pas ? üôÇ*

##### 4. Optimisation des Transformations des Donn√©es

Dans certains cas, nous devons appliquer des transformations sp√©cifiques aux donn√©es CSV. Pour cela, nous avons identifi√© deux approches possibles :

-- **Modification de la Fonction GetData**

Une premi√®re approche consiste √† int√©grer les transformations directement dans la fonction GetData :

```powerquery ins={"Ajouter les √©tapes de transformation sp√©cifiques aux donn√©es CSV ici":14-17} del={"Supprimer":28} ins={"Remplacer":29}
let
    GetData = (NumberColumnsCSV as number, MySQLQuery as text) =>
        let
            CsvSource = Csv.Document(
                Web.Contents(URL_CSV_FILE),
                [
                    Delimiter = ",",
                    Columns = NumberColumnsCSV,
                    Encoding = 1252,
                    QuoteStyle = QuoteStyle.None
                ]
            ),
            CsvPromotedHeaders = Table.PromoteHeaders(CsvSource, [PromoteAllScalars = true]),

            CsvReplacedValue = Table.ReplaceValue(
                CsvPromotedHeaders, ".", ",", Replacer.ReplaceText, {"my_column_numeric"}
            ),

            SourceMySQL = MySQL.Database(
                MySQL_HOSTNAME,
                MySQL_DATABASE_NAME,
                [
                    ReturnSingleDatabase = true,
                    Query = MySQLQuery,
                    CreateNavigationProperties = false
                ]
            ),
            Result = if IS_PRODUCTION then SourceMySQL else CsvPromotedHeaders
            Result = if IS_PRODUCTION then SourceMySQL else CsvReplacedValue
        in
            Result
in
    GetData
```

Cependant, cette approche n'est pas recommand√©e car elle va √† l'encontre du principe de responsabilit√© unique : une fonction devrait id√©alement n'avoir qu'une seule responsabilit√©.

-- **Transformation dans la Requ√™te MyData**

Une approche plus √©l√©gante consiste √† s√©parer la r√©cup√©ration des donn√©es de leur transformation. Mettons √† jour notre requ√™te "MyData" pour appliquer les transformations sp√©cifiques aux donn√©es CSV :

```powerquery ins={3-9}
let
    Source = GetData(5, MySQL_QUERY),
    ReplacedValue = Table.ReplaceValue(
        Source, ".", ",", Replacer.ReplaceText, {"my_column_numeric"}
    ),
    ChangedType = Table.TransformColumnTypes(
        if IS_PRODUCTION then Source else ReplacedValue,
        {{"my_column_numeric", type number}}
    )
in
    ChangedType
```

Cette seconde approche offre plusieurs avantages :

- S√©paration claire des responsabilit√©s
- Meilleure maintenabilit√© du code
- Plus grande flexibilit√© pour modifier les transformations
- Possibilit√© d'appliquer des transformations conditionnelles selon l'environnement

<br />
### Conclusion

Au final, nous avons trouv√© une solution simple mais puissante pour contourner les d√©fis de connexion et de performance. En quelques √©tapes, nous avons transform√© un probl√®me complexe en une approche flexible qui nous permet de travailler efficacement, que ce soit en local ou en production. Cette approche peut facilement √™tre adapt√©e et √©tendue pour r√©pondre √† d'autres besoins par exemple ajout de nouveaux environnements (test, pr√©-production) ou support d'autres sources de donn√©es (PostgreSQL, Oracle, etc.).
